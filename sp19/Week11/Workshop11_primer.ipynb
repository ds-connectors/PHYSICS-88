{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Workshop 11: Linear Algebra Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A matrix is a collection of numbers in a grid of dimensions $m$ by $n$. This means the grid has $m$ rows and $n$ columns. Example:\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "3 & 1 \\\\\n",
    "4 & -0.5 \\\\\n",
    "\\pi/2 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "This matrix has $m=3$ rows and $n=2$ columns. A single element of the matrix $A$ is denoted as $A_{ij}$ where $i$ denotes the row of the element and $j$ denotes the column. For example $A_{12}$ has the value 1 above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Addition & Subtraction\n",
    "Let us define addition and subtraction on matrices:\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "3 & 1 \\\\\n",
    "4 & -0.5 \\\\\n",
    "\\end{pmatrix} + \n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "\\end{pmatrix} \n",
    " = \n",
    " \\begin{pmatrix}\n",
    "4 & 1 \\\\\n",
    "4 & 0.5 \\\\\n",
    "\\end{pmatrix} \n",
    "$$\n",
    "\n",
    "Symbolically, if the first matrix is $A$, the second matrix is $B$, and the third matrix is $C$, then the element $C_{ij} = A_{ij} + B_{ij}$. This means that you cannot add or subtract matrices with different dimensions (for example, you cannot add a $3\\times 2$ matrix to a $5\\times 5$ matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scalar Multiplication\n",
    "We multiply matrices and vectors by scalars as follows. Let\n",
    "$$A = \\begin{pmatrix}\n",
    "3 & 1 \\\\\n",
    "4 & -0.5 \\\\\n",
    "\\end{pmatrix}$$\n",
    "Then $5A$ is\n",
    "$$5A = \\begin{pmatrix}\n",
    "5\\times 3 & 5\\times 1 \\\\\n",
    "5\\times 4 & 5 \\times (-0.5) \\\\\n",
    "\\end{pmatrix}=\\begin{pmatrix}\n",
    "15 & 5 \\\\\n",
    "20 & -2.5 \\\\\n",
    "\\end{pmatrix}$$\n",
    "and for a vector, if\n",
    "$$v = \\begin{pmatrix}\n",
    "1 \\\\\n",
    "-1 \\\\\n",
    "\\end{pmatrix}$$\n",
    "then $5v$ is\n",
    "$$5v = \\begin{pmatrix}\n",
    "5 \\\\\n",
    "-5 \\\\\n",
    "\\end{pmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "The definition of multiplication is not element-wise like it is for addition above. Instead, the formula for the product $C$ of two matrices $A$ and $B$ is\n",
    "\n",
    "$$C_{ij} = \\sum_k A_{ik}B_{kj}$$\n",
    "\n",
    "Let us put this abstract formula to use. If \n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "3 & 1 \\\\\n",
    "4 & -0.5 \\\\\n",
    "\\end{pmatrix}, B = \n",
    "\\begin{pmatrix}\n",
    "0 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "then the product denoted $AB$ is another $2\\times 2$ matrix $C$. Let us compute one element $C_{11}$ using the formula above. \n",
    "\n",
    "$$C_{11} = A_{11}B_{11} + A_{12}B_{21} = (3)(0) + (1)(1) = 1$$\n",
    "\n",
    "Test your understanding by computing the other 3 elements. You should ultimately find that\n",
    "\n",
    "$$C = \\begin{pmatrix}\n",
    "1 & 3 \\\\\n",
    "-0.5 & 4 \\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "You can also multiply a matrix by a vector this way. Multiplying an $m \\times n $ matrix by a vector of $n$ elements returns another vector of $m$ elements. For example, if\n",
    "\n",
    "$$A = \\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "2 & 1 \\\\\n",
    "0 & -1 \\\\\n",
    "\\end{pmatrix}, v = \\begin{pmatrix}\n",
    "1 \\\\\n",
    "-1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "then\n",
    "\n",
    "$$Av = \\begin{pmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "This means the following:\n",
    "1. If matrix $A$ has dimensions $m \\times n$ and matrix $B$ has dimensions $o \\times p$ and $n\\neq o$, they cannot be multiplied together. If $v$ is a vector of length $o\\neq n$, $A$ cannot be multiplied by $v$.\n",
    "1. Generally, $AB \\neq BA$. Suppose $A$ has dimensions $m \\times n$ and $B$ has dimensions $n \\times p$ and $p\\neq m$. Then $AB$ can be calculated and the final result has dimensions $m\\times p$, but $BA$ cannot be calculated.\n",
    "\n",
    "**For the remainder of the document, we will only discuss square matrices, meaning the number of rows $m$ equals the number of columns $n$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The identity matrix\n",
    "\n",
    "The identity matrix is the matrix $I$ such that for an $m\\times m$ matrix $A$, $AI = A$. The identity is then an $m\\times m$ matrix where \n",
    "$$I_{ii} = 1, I_{ij} = 0 \\text{ for } i\\neq j$$\n",
    "For example, for $m=3$, the identity matrix is\n",
    "$$I = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "\\end{pmatrix}$$\n",
    "(Check for yourself, using the definition of multiplication above, that it really does satsify $AI = A$ for any $m \\times m$ matrix $A$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The inverse of a matrix\n",
    "\n",
    "Now that we have the identity, we can define the inverse. The inverse of a matrix $A$ denoted $A^{-1}$ is the matrix such that\n",
    "\n",
    "$$A^{-1}A = I$$\n",
    "\n",
    "Note that in general, $(A^{-1})_{ij}\\neq 1/A_{ij}$. Instead, this is actually a fairly difficult thing to do and most importantly, *the inverse does not always exist*. When the inverse does not exist, we say the matrix is **singular**. One way to check whether a matrix is **singular** is by computing something called the **determinant**. The determinant can be defined in many ways. Here we will define it as a mysterious, recursive formula and do an example with a $2\\times 2$ matrix. \n",
    "\n",
    "First start with a $1\\times 1$ matrix $A$:\n",
    "\n",
    "$$A  = (3)$$\n",
    "\n",
    "The determinant of $A$, $\\det(A)$ is just equal its one value: $\\det(A) = 3$. Now let us move up to a $2\\times 2$ matrix $B$. The determinant of a $2\\times 2$ matrix\n",
    "$$A = \\begin{pmatrix}\n",
    "a & b \\\\\n",
    "c & d\\\\\n",
    "\\end{pmatrix}$$\n",
    "is given by \n",
    "$$\\det(A) = ad - bc$$\n",
    "Now let us move up to a $3\\times 3$ matrix $A$:\n",
    "$$A = \\begin{pmatrix}\n",
    "a_{11} & a_{12} & a_{13} \\\\\n",
    "a_{21} & a_{22} & a_{23} \\\\\n",
    "a_{31} & a_{32} & a_{33} \\\\\n",
    "\\end{pmatrix}$$\n",
    "The determinant of this matrix can be found using the so-called \"cofactor expansion\":\n",
    "$$\\det(A) = a_{11} (a_{22}a_{33} - a_{23}a_{32}) - a_{12}(a_{21}a_{33} - a_{23}a_{31}) + a_{13}(a_{21}a_{32}-a_{22}a_{31})$$\n",
    "This looks complicated but actually let me show you what is going on inside it. Look at the first term, which begins with $a_{11}$ (row 1, column 1). In this term, $a_{11}$ is multiplied by $a_{22}a_{33} - a_{23}a_{32}$. If you look carefully, this is the determinant of the $2\\times 2$ matrix\n",
    "$$\\begin{pmatrix}\n",
    "a_{22} & a_{23} \\\\\n",
    "a_{32} & a_{33} \\\\\n",
    "\\end{pmatrix}$$\n",
    "which is the matrix you would get from $A$ if you removed the first row and the first column from $A$. Look at the second term in the cofactor expansion, which begins with $a_{12}$ (row 1, column 2). In this term, $a_{12}$ is multiplied by $a_{21}a_{33} - a_{23}a_{31}$. This is the determinant of hte $2 \\times 2$ matrix \n",
    "$$\\begin{pmatrix}\n",
    "a_{21} & a_{23} \\\\\n",
    "a_{31} & a_{33} \\\\\n",
    "\\end{pmatrix}$$\n",
    "which is the matrix you would get from $A$ if you removed the first row and the second column from $A$. So each term in the expansion is defined in terms of the determinants of smaller matrices. As a result, it is generally challenging to compute determinants by hand for anything larger than a $3 \\times 3$ matrix, but you could write a *recursive function* in Python to do it...if you want.\n",
    "\n",
    "Now that we have a method, if unpleasant, to calculate the determinant, here is one thing it can tell us: if $\\det(A) = 0$, $A$ does not have an inverse (it is singular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The linear systems problem\n",
    "\n",
    "Suppose we have two lines\n",
    "\n",
    "$$y = 3x + 1$$\n",
    "$$y = -2x + 2$$\n",
    "\n",
    "At what point $x,y$ do they intersect? We can solve this problem using the ideas above. Rearrange those two equations to put all of the variables $(x,y)$ on one side:\n",
    "\n",
    "$$-3x + y = 1$$\n",
    "$$2x + y = 2$$\n",
    "\n",
    "Using the definition of matrix multiplication above, verify that this is the same as writing it as\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "-3 & 1 \\\\\n",
    "2 & 1 \\\\\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "\\end{pmatrix}= \\begin{pmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Let\n",
    "$$A=\\begin{pmatrix}\n",
    "-3 & 1 \\\\\n",
    "2 & 1 \\\\\n",
    "\\end{pmatrix}, v=\\begin{pmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "\\end{pmatrix}, b= \\begin{pmatrix}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "\\end{pmatrix} $$\n",
    "This problem is the matrix equation\n",
    "$$Av = b$$\n",
    "and we are trying to solve for $v$. Here's one way we can do it. Assume that $A^{-1}$ exists. Then multiply the LHS and the RHS of the equation on the left:\n",
    "\n",
    "$$A^{-1}A v = A^{-1} b$$\n",
    "\n",
    "$A^{-1}A = I$ by definition, so\n",
    "\n",
    "$$v = A^{-1} b$$\n",
    "So to find the intersection, invert $A$ and multiply $b$! Here is a snippet of code implementing all of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.matrix([[-3, 1], [2, 1]])\n",
    "b = np.matrix([[1],[2]])\n",
    "v = np.linalg.inv(A) * b\n",
    "print(\"x = %.2f\" % v[0])\n",
    "print(\"y = %.2f\" % v[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check that the values of $x$ and $y$ obtained above really do correspond to the intersection of the two lines. What happens if you tried to calculate the intersection of two lines which have the same slope?\n",
    "\n",
    "This corresponds to another possibility we have overlooked--the inverse of $A$ will not exist, or, in the language above, it has zero determinant. \n",
    "\n",
    "If you have studied linear algebra, you should recognize that when we make the slope of the two lines the same, the rows of $A$ become linearly dependent on each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The eigenvalue problem (\"diagonalization\")\n",
    "\n",
    "Probably the most famous problem in all of science is the eigenvalue problem. It is ubiquitous across fields and is the defining problem of quantum mechanics. In this problem, we change the problem slightly from before. For a given $A$, we try to look for scalar values $\\lambda$ and vectors $v$ that satisfy the matrix equation\n",
    "\n",
    "$$A v = \\lambda v$$\n",
    "\n",
    "Let us look at a simple example:\n",
    "$$A = \\begin{pmatrix}\n",
    "0 & 1  \\\\\n",
    "1 & 0 \\\\\n",
    "\\end{pmatrix}$$\n",
    "The eigenvectors of this matrix are \n",
    "$$v_1 =  \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n",
    "1 \\\\\n",
    "1 \\\\\n",
    "\\end{pmatrix}\\text{ and }\n",
    "v_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n",
    "1 \\\\\n",
    "-1 \\\\\n",
    "\\end{pmatrix}$$\n",
    "If you multiply $A$ by $v_1$ you get $Av_1 = v_1$ and if you multiply $A$ by $v_2$ you get $Av_2 = -v_2$ (check these for yourself by doing the multiplications). This means that the eigenvalue $\\lambda_1$ corresponding to the eigenvector $v_1$ is $\\lambda_1 = 1$, and the eigenvalue $\\lambda_2$ corresponding to the eigenvector $v_2$ is $\\lambda_2 = -1$.\n",
    "\n",
    "One geometric intuition for what an eigenvector is that it is a vector whose direction is not changed by the action of $A$: only its length is rescaled by a factor of $\\lambda$. \n",
    "\n",
    "An $m \\times m$ matrix can have at most $m$ eigenvectors (and consequently it can have at most $m$ unique eigenvalues). It can also have $m$ eigenvectors but fewer than $m$ eigenvalues--that is, multiple eigenvectors may have the same eigenvalue (in physics, this is called \"degeneracy\").\n",
    "\n",
    "This problem is referred to as \"diagonalization\" because once you have found all of the eigenvectors $v_i$ and their eigenvalues $\\lambda_i$, you can decompose $A$ as\n",
    "$$A = U D U^\\dagger$$\n",
    "where \n",
    "$$ D = \\begin{pmatrix}\n",
    "\\lambda_1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & \\lambda_2 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\lambda_{m-1} & 0 \\\\\n",
    "0 & 0 & \\cdots & 0 & \\lambda_m \\\\\n",
    "\\end{pmatrix}$$\n",
    "and the columns of $U$ are formed by\n",
    "$$U = \\begin{pmatrix}\n",
    "v_1 & v_2 & \\cdots & v_{m-1} & v_m\n",
    "\\end{pmatrix}$$\n",
    "(remember each $v_i$ is a column of $m$ elements). And $U^\\dagger$ denotes the conjugate transpose of $U$. $D$ is a \"diagonal\" matrix becaues it has non-zero elements only along its diagonal, so this process is called \"diagonalization\".\n",
    "\n",
    "It turns out that the determinant of a matrix, defined above, is also equal to the product of its eigenvalues.\n",
    "$$\\det(A) = \\lambda_1 \\times \\lambda_2 \\dots \\times \\lambda_m$$\n",
    "So when $\\det(A) = 0$ (the matrix is *singular*), this means that at least one eigenvalue is equal to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Final remarks\n",
    "\n",
    "There are literally tomes and tomes about different algorithms to solve the two problems listed above because inverting a matrix and directly diagonalizing a matrix is usually computationally expensive. Here we have only discussed the mathematical aspect of it, but if you use some existing linear algebra package to solve one of these problems, most of the time, they will do something more sophisticated than what is described above.\n",
    "\n",
    "The reason people have invested so much into improving algorithms for these processes is that they show up in nearly every field of study, so if you have not studied linear algebra, I encourage you to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
